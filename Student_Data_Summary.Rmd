---
title: "IST 707 Final Project - Student Educational Outcomes"
author: "Christoper Murphy, Padmaja Kurumaddali, La Monte Yarroll"
date: "September 07, 2024"
output: word_document

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r include=FALSE}
#first, install and load required libraries
#using function provided by Professor Gary Krudys.

#specify the packages needed
packages=c("tidyverse", "ggplot2", "mclust", "rpart", "rpart.plot", "caret", "arules", "arulesViz", "corrplot", "Hmisc", "cluster", "knitr", "factoextra", "randomForest", "e1071", "pheatmap","pROC")

#use this function to check if each package is on the local machine
#if a package is installed, it will be loaded
#if any are not, the missing package(s) will be installed and loaded
package.check <- lapply(packages, FUN = function(x) {
  if (!require(x, character.only = TRUE)) {
    install.packages(x, dependencies = TRUE)
    library(x, character.only = TRUE)
  }
})

#verify they are loaded
search()
```


```{r eval=FALSE, include=FALSE}
#References used to inform code choices:

```


# Introduction
 

# Analysis and Models


## About the data


### Dataset Summary
The following dataset was located on Kaggle at the following page:

https://www.kaggle.com/code/mdismielhossenabir/student-s-dropout-and-academic-success

The original source at UCI is here:

https://archive.ics.uci.edu/dataset/697/predict+students+dropout+and+academic+success

This dataset contains information on students' marital status, application details, previous qualifications, family background, admission grades, financial status, and academic performance. The target variable indicates whether a student dropped out or achieved academic success. The data spans multiple semesters and includes economic indicators such as unemployment rate, inflation rate, and GDP. Researchers can leverage this dataset to develop models for predicting dropout and academic success, contributing to the understanding of factors influencing educational outcomes.


### Data Retrieval
Data structure structure when read in from the .CSV file:

```{r echo=FALSE}
filePath = "studentdata.csv"
studentSuccessData = read.csv2(filePath, stringsAsFactors = FALSE, dec=".")
str(studentSuccessData)
```



#### Initial Data Sample
A sample set of records:
```{r echo=FALSE}
head(studentSuccessData, 5)
```

#### Check for Missing Values

```{r echo=FALSE}
colSums(is.na(studentSuccessData))
```



\pagebreak
### Data Attribute Summary

The Kaggle data card can also be found on the following page
https://www.kaggle.com/code/mdismielhossenabir/student-s-dropout-and-academic-success/input

### Attribute Summary:
* Marital Status: The marital status of the student
* Application mode: The mode through which the student applied for admission
* Application order: The order in which the student applied for admission.
* Course: The academic course or program the student is enrolled in.
* Daytime/evening attendance: The attendance mode of the student (e.g., Daytime, Evening).
* Previous qualification: The highest academic qualification the student attained before the current enrollment.
* Previous qualification (grade): The grade or score achieved in the previous qualification.
* Nacionality: The nationality of the student.
* Mother's qualification: The highest academic qualification of the student's mother.
* Father's qualification: The highest academic qualification of the student's father.
* Mother's occupation: The occupation of the student's mother.
* Father's occupation: The occupation of the student's father.
* Admission grade: The grade or score obtained during the admission process.
* Displaced: Indicates whether the student has been displaced from their previous location.
* Educational special needs: Flags if the student has any educational special needs.
* Debtor: Indicates if the student is a debtor.
* Tuition fees up to date: Indicates whether the student's tuition fees are up to date.
* Gender: The gender of the student.
* Scholarship holder: Flags if the student is a holder of a scholarship.
* Age at enrollment: The age of the student at the time of enrollment.
* International: Indicates if the student is an international student.
* Curricular units 1st sem (credited): The number of curricular units credited in the first semester.
* Curricular units 1st sem (enrolled): The number of curricular units enrolled in the first semester.
* Curricular units 1st sem (evaluations): The number of evaluations conducted in the first semester.
* Curricular units 1st sem (approved): The number of curricular units approved in the first semester.
* Curricular units 1st sem (grade): The overall grade for curricular units in the first semester.
* Curricular units 1st sem (without evaluations): Curricular units in the first semester without evaluations.
* Curricular units 2nd sem (credited): The number of curricular units credited in the second semester.
* Curricular units 2nd sem (enrolled): The number of curricular units enrolled in the second semester.
* Curricular units 2nd sem (evaluations): The number of evaluations conducted in the second semester.
* Curricular units 2nd sem (approved): The number of curricular units approved in the second semester.
* Curricular units 2nd sem (grade): The overall grade for curricular units in the second semester.
* Curricular units 2nd sem (without evaluations): Curricular units in the second semester without evaluations.
* Unemployment rate: The unemployment rate at the time of data collection.
* Inflation rate: The inflation rate at the time of data collection.
* GDP: The Gross Domestic Product at the time of data collection.
* Target: The target variable indicating student outcome (e.g., Dropout, Academic Success).



\pagebreak

### Data Transformations

First, fill missing values with the mean for numeric columns and mode for categorical columns.

```{r include=FALSE}
# Perform necessary transformations

# Fill missing values with the mean for numeric columns and mode for categorical columns

studentSuccessData <- studentSuccessData %>%

  mutate(across(where(is.numeric), ~ ifelse(is.na(.), mean(., na.rm = TRUE), .))) %>%

  mutate(across(where(is.character), ~ ifelse(is.na(.), Mode(.), .)))
 
# Function to calculate mode

Mode <- function(x) {

  ux <- unique(x)

  ux[which.max(tabulate(match(x, ux)))]

}
```


Second, convert categorical columns to type Factor.

```{r include=FALSE}

# Convert categorical columns to factor type

studentSuccessData <- studentSuccessData %>%

  mutate(

    Marital.status = factor(
      Marital.status,
      levels = c(1, 2, 3, 4, 5, 6),
      labels = c("Single", "Married", "Widower", "Divorced", "Facto Union", "Legally Separated")),

    Application.mode = factor(
      Application.mode,
      levels = c(1, 2, 5, 7, 10, 15, 16, 17, 18, 26, 27, 39, 42, 43, 44, 51, 53, 57),
      labels = c(
        "1st phase - general contingent",
        "Ordinance No. 612/93",
        "1st phase - special contingent (Azores Island)",
        "Holders of other higher courses",
        "Ordinance No. 854-B/99",
        "International student (bachelor)",
        "1st phase - special contingent (Madeira Island)",
        "2nd phase - general contingent",
        "3rd phase - general contingent",
        "Ordinance No. 533-A/99, item b2) (Different Plan)",
        "Ordinance No. 533-A/99, item b3 (Other Institution)",
        "Over 23 years old",
        "Transfer",
        "Change of course",
        "Technological specialization diploma holders",
        "Change of institution/course",
        "Short cycle diploma holders",
        "Change of institution/course (International)")),

    Application.order = factor(Application.order, ordered=TRUE, levels = c(1, 2, 3, 4, 5, 6), labels = c("1st", "2nd", "3rd", "4th", "5th", "6th")),
    
    Target = factor(Target),

    Course = factor(Course, levels = c(33,171,8014,9003,9070,9085,9119,9130,9147,9238,9254,9500,9556,9670,9773,9853,9991), labels = c(
      "Biofuel Production Technologies",
      "Animation and Multimedia Design",
      "Social Service (evening attendance) ",
      "Agronomy",
      "Communication Design",
      "Veterinary Nursing",
      "Informatics Engineering",
      "Equinculture",
      "Management",
      "Social Service",
      "Tourism",
      "Nursing",
      "Oral Hygiene",
      "Advertising and Marketing Management",
      "Journalism and Communication",
      "Basic Education",
      "Management (evening attendance)")),


    Previous.qualification = factor(
      Previous.qualification,
      levels = c(1, 2, 3, 4, 5, 6, 9, 10, 12, 14, 15, 19, 38, 39, 40, 42, 43),
      labels = c(
        "Secondary education",
        "Higher education - bachelor's degree",
        "Higher education - degree",
        "Higher education - master's",
        "Higher education - doctorate",
        "Frequency of higher education",
        "12th year of schooling - not completed",
        "11th year of schooling - not completed",
        "Other - 11th year of schooling",
        "10th year of schooling",
        "10th year of schooling - not completed",
        "Basic education 3rd cycle (9th/10th/11th year) or equiv.",
        "Basic education 2nd cycle (6th/7th/8th year) or equiv.",
        "Technological specialization course",
        "Higher education - degree (1st cycle)",
        "Professional higher technical course",
        "Higher education - master (2nd cycle)")),

    Nacionality = factor(
      Nacionality,
      levels = c(1, 2, 6, 11, 13, 14, 17, 21, 22, 24, 25, 26, 32, 41, 62, 100, 101, 103, 105, 108, 109),
      labels = c(
        "Portuguese",
        "German",
        "Spanish",
        "Italian",
        "Dutch",
        "English",
        "Lithuanian",
        "Angolan",
        "Cape Verdean",
        "Guinean",
        "Mozambican",
        "Santomean",
        "Turkish",
        "Brazilian",
        "Romanian",
        "Moldova (Republic of)",
        "Mexican",
        "Ukrainian",
        "Russian",
        "Cuban",
        "Colombian")),

    # Causes the error.
#     Mother.s.qualification <- ordered(Mother.s.qualification, levels = c(1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 14, 18, 19, 22, 26, 27, 29, 30, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44), labels = c(
#   "Secondary Education - 12th Year of Schooling or Eq.",
#   "Higher Education - Bachelor's Degree",
#   "Higher Education - Degree",
#   "Higher Education - Master's",
#   "Higher Education - Doctorate",
#   "Frequency of Higher Education",
#   "12th Year of Schooling - Not Completed",
#   "11th Year of Schooling - Not Completed",
#   "7th Year (Old)",
#   "Other - 11th Year of Schooling",
#   "10th Year of Schooling",
#   "General commerce course",
#   "Basic Education 3rd Cycle (9th/10th/11th Year) or Equiv.",
#   "Technical-professional course",
#   "7th year of schooling",
#   "2nd cycle of the general high school course",
#   "9th Year of Schooling - Not Completed",
#   "8th year of schooling",
#   "Unknown",
#   "Can't read or write",
#   "Can read without having a 4th year of schooling",
#   "Basic education 1st cycle (4th/5th year) or equiv.",
#   "Basic Education 2nd Cycle (6th/7th/8th Year) or Equiv.",
#   "Technological specialization course",
#   "Higher education - degree (1st cycle)",
#   "Specialized higher studies course",
#   "Professional higher technical course",
#   "Higher Education - Master (2nd cycle)",
#   "Higher Education - Doctorate (3rd cycle)"
# )),
# 
#  Father.s.qualification <- ordered(Father.s.qualification, levels = c(1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 18, 19, 20, 22, 25, 26, 27, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44), labels = c(
#   "Secondary Education - 12th Year of Schooling or Eq.",
#   "Higher Education - Bachelor's Degree",
#   "Higher Education - Degree",
#   "Higher Education - Master's",
#   "Higher Education - Doctorate",
#   "Frequency of Higher Education",
#   "12th Year of Schooling - Not Completed",
#   "11th Year of Schooling - Not Completed",
#   "7th Year (Old)",
#   "Other - 11th Year of Schooling",
#   "2nd year complementary high school course",
#   "10th Year of Schooling",
#   "General commerce course",
#   "Basic Education 3rd Cycle (9th/10th/11th Year) or Equiv.",
#   "Complementary High School Course",
#   "Technical-professional course",
#   "Complementary High School Course - not concluded",
#   "7th year of schooling",
#   "2nd cycle of the general high school course",
#   "9th Year of Schooling - Not Completed",
#   "8th year of schooling",
#   "General Course of Administration and Commerce",
#   "Supplementary Accounting and Administration",
#   "Unknown",
#   "Can't read or write",
#   "Can read without having a 4th year of schooling",
#   "Basic education 1st cycle (4th/5th year) or equiv.",
#   "Basic Education 2nd Cycle (6th/7th/8th Year) or Equiv.",
#   "Technological specialization course",
#   "Higher education - degree (1st cycle)",
#   "Specialized higher studies course",
#   "Professional higher technical course",
#   "Higher Education - Master (2nd cycle)",
#   "Higher Education - Doctorate (3rd cycle)"
# )),
# 
# Mother.s.occupation <- ordered(Mother.s.occupation, levels = c(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 90, 99, 122, 123, 125, 131, 132, 134, 141, 143, 144, 151, 152, 153, 171, 173, 175, 191, 192, 193, 194), labels = c(
#   "Student",
#   "Representatives of the Legislative Power and Executive Bodies, Directors, Directors and Executive Managers",
#   "Specialists in Intellectual and Scientific Activities",
#   "Intermediate Level Technicians and Professions",
#   "Administrative staff",
#   "Personal Services, Security and Safety Workers and Sellers",
#   "Farmers and Skilled Workers in Agriculture, Fisheries and Forestry",
#   "Skilled Workers in Industry, Construction and Craftsmen",
#   "Installation and Machine Operators and Assembly Workers",
#   "Unskilled Workers",
#   "Armed Forces Professions",
#   "Other Situation",
#   "(blank)",
#   "Health professionals",
#   "Teachers",
#   "Specialists in information and communication technologies (ICT)",
#   "Intermediate level science and engineering technicians and professions",
#   "Technicians and professionals, of intermediate level of health",
#   "Intermediate level technicians from legal, social, sports, cultural and similar services",
#   "Office workers, secretaries in general and data processing operators",
#   "Data, accounting, statistical, financial services and registry-related operators",
#   "Other administrative support staff",
#   "Personal service workers",
#   "Sellers",
#   "Personal care workers and the like",
#   "Skilled construction workers and the like, except electricians",
#   "Skilled workers in printing, precision instrument manufacturing, jewelers, artisans and the like",
#   "Workers in food processing, woodworking, clothing and other industries and crafts",
#   "Cleaning workers",
#   "Unskilled workers in agriculture, animal production, fisheries and forestry",
#   "Unskilled workers in extractive industry, construction, manufacturing and transport",
#   "Meal preparation assistants"
# )),
# 
#  Father.s.occupation <- factor(Father.s.occupation,
# levels = c(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 90, 99, 101, 102, 103, 112, 114, 121, 122, 123, 124, 131, 132, 134, 135, 141, 143, 144, 151, 152, 153, 154, 161, 163, 171, 172, 174, 175, 181, 182, 183, 192, 193, 194, 195), labels = c(
#   "Student",
#   "Representatives of the Legislative Power and Executive Bodies, Directors, Directors and Executive Managers",
#   "Specialists in Intellectual and Scientific Activities",
#   "Intermediate Level Technicians and Professions",
#   "Administrative staff",
#   "Personal Services, Security and Safety Workers and Sellers",
#   "Farmers and Skilled Workers in Agriculture, Fisheries and Forestry",
#   "Skilled Workers in Industry, Construction and Craftsmen",
#   "Installation and Machine Operators and Assembly Workers",
#   "Unskilled Workers",
#   "Armed Forces Professions",
#   "Other Situation",
#   "(blank)",
#   "Armed Forces Officers",
#   "Armed Forces Sergeants",
#   "Other Armed Forces personnel",
#   "Directors of administrative and commercial services",
#   "Hotel, catering, trade and other services directors",
#   "Specialists in the physical sciences, mathematics, engineering and related techniques",
#   "Health professionals",
#   "Teachers",
#   "Specialists in finance, accounting, administrative organization, public and commercial relations",
#   "Intermediate level science and engineering technicians and professions",
#   "Technicians and professionals, of intermediate level of health",
#   "Intermediate level technicians from legal, social, sports, cultural and similar services",
#   "Information and communication technology technicians",
#   "Office workers, secretaries in general and data processing operators",
#   "Data, accounting, statistical, financial services and registry-related operators",
#   "Other administrative support staff",
#   "Personal service workers",
#   "Sellers",
#   "Personal care workers and the like",
#   "Protection and security services personnel",
#   "Market-oriented farmers and skilled agricultural and animal production workers",
#   "Farmers, livestock keepers, fishermen, hunters and gatherers, subsistence",
#   "Skilled construction workers and the like, except electricians",
#   "Skilled workers in metallurgy, metalworking and similar",
#   "Skilled workers in electricity and electronics",
#   "Workers in food processing, woodworking, clothing and other industries and crafts",
#   "Fixed plant and machine operators",
#   "Assembly workers",
#   "Vehicle drivers and mobile equipment operators",
#   "Unskilled workers in agriculture, animal production, fisheries and forestry",
#   "Unskilled workers in extractive industry, construction, manufacturing and transport",
#   "Meal preparation assistants",
#   "Street vendors (except food) and street service providers"
# )),
# Displaced <- factor(Displaced, levels = c(1, 0), labels = c("yes", "no")),
# Educational.special.needs <- factor(Educational.special.needs, levels = c(1, 0), labels = c("yes", "no")),
# Debtor <- factor(Debtor, levels = c(1, 0), labels = c("yes", "no")),
# Tuition.fees.up.to.date <- factor(Tuition.fees.up.to.date, levels = c(1, 0), labels = c("yes", "no")),
# Gender <- factor(Gender, levels = c(1, 0), labels = c("yes", "no")),
# Scholarship.holder <- factor(Scholarship.holder, levels = c(1, 0), labels = c("yes", "no")),
# International <- factor(International, levels = c(1, 0), labels = c("yes", "no")),
    # Daytime.evening.attendance. <- factor(Daytime.evening.attendance., levels = c(1, 0), labels = c("daytime", "evening"))
)
```


Show the structure of the data frame after transformation:

```{r}
#validate structure after attribute transformation
str(studentSuccessData)
```



Show the summary of the data frame after transformation:

```{r}
summary(studentSuccessData)
```


Finally, remove any incomplete observations from the data frame.

```{r include=FALSE}

# Remove rows with any NA values
studentSuccessData <- studentSuccessData[complete.cases(studentSuccessData), ]

```


#### Continuous Attributes

These attributes are continuous variables:
["Unemployment.rate", "Inflation.rate", "GDP"]                            


\pagebreak
### Exploratory Data Analysis

Divide the data into a reserved test set (30%) and a train set (70%).

```{r include=FALSE}
set.seed(711)
ind <- sample(c(TRUE, FALSE), size=nrow(studentSuccessData), replace=TRUE, prob=c(0.7, 0.3))
train <- studentSuccessData[ind, ]
test <- studentSuccessData[!ind, ]
```


Copy the test and train datasets to create an SVM-specific test and train data sets.

```{r include=FALSE}
#capture new data frames to isolate to SVM
svm_train <- train
svm_test <- test

# remove labels from the test set
svm_test_label <- svm_test$Target

svm_test <- svm_test[,-1] 
```


The following plots describe the attribute distributions.

```{r}
 
columns <- colnames(train)
# Loop through each column and create a plot
for (col in columns) {
  # Check if the column is numeric or categorical
  if (is.numeric(train[[col]])) {
    # Create a histogram for numeric columns
    p <- ggplot(train, aes_string(x = col)) +
      geom_histogram(binwidth = 1, fill = "blue", color = "black") +
      ggtitle(paste("Histogram of", col)) +
      theme_minimal()
  } else {
    # Create a bar plot for categorical columns
    p <- ggplot(train, aes_string(x = col)) +
      geom_bar(fill = "blue", color = "black") +
      ggtitle(paste("Bar Plot of", col)) +
      theme_minimal()
  }
  # Print the plot
  print(p)
}
```


the following graph shows an example of a small multiple from the dataset.

```{r}
#base_graph <- ggplot(train, aes(Target)) + geom_bar()

#base_graph + facet_grid(cols=vars(Marital.status), rows=vars(Nacionality))
```

### Correllations

```{r}
train_m <- sapply(train, as.numeric)
train_complete <- complete.cases(train_m)
train_m <- train_m[train_complete, ]
train.cor <- cor(train_m, method=c("pearson"))
corrplot(train.cor, tl.cex = 0.3)
heatmap(train.cor)
```


### Bi-Variate EDA

```{r}

# Plot for Age and Target

ggplot(train, aes(x = Age.at.enrollment, y = Target)) +
  geom_point() +
  geom_smooth(method = "lm", col = "blue") +
  labs(title = "Scatter Plot of Age.at.enrollment  vs Target",
       x = "Age.at.enrollment ",
       y = "Target") +
  theme_minimal()

```


### 2. Mother's Qualification and Target

```{r}
# Bar plot for Mother's Qualification and Target
ggplot(train, aes(x = factor(Mother.s.qualification), fill = factor(Target))) +
  geom_bar(position = "dodge") +
  labs(title = "Bar Plot of Mother's Qualification vs Target",
       x = "Mother's Qualification",
       fill = "Target") +
  theme_minimal() +
  scale_fill_brewer(palette = "Set3") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

### 3. Father's Qualification and Target
```{r}
# Bar plot for Father's Qualification and Target
ggplot(train, aes(x = factor(Father.s.qualification), fill = factor(Target))) +
  geom_bar(position = "dodge") +
  labs(title = "Bar Plot of Father's Qualification vs Target",
       x = "Father's Qualification",
       fill = "Target") +
  theme_minimal() +
  scale_fill_manual(values = c("#DC143C", "#1f77b4", "#2ca02c"))  

```

### 4. Mother's Occupation, Father's Occupation, and Target
```{r}
# Bar plot for Father's Occupation and Target
ggplot(train, aes(x = factor(Father.s.occupation), fill = factor(Target))) +
  geom_bar(position = "dodge") +
  labs(title = "Bar Plot of Father's Occupation vs Target",
       x = "Father's Occupation",
       fill = "Target") +
  theme_minimal() +
  scale_fill_brewer(palette = "Set3") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Bar plot for Mother's Occupation and Target
ggplot(train, aes(x = factor(Mother.s.occupation), fill = factor(Target))) +
  geom_bar(position = "dodge") +
  labs(title = "Bar Plot of Mother's Occupation vs Target",
       x = "Mother's Occupation",
       fill = "Target") +
  theme_minimal() +
  scale_fill_brewer(palette = "Set3") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

### 5. Previous Qualification and Target
```{r}
# Bar plot for Previous Qualification and Target
ggplot(train, aes(x = factor(Previous.qualification), fill = factor(Target))) +
  geom_bar(position = "dodge")  +
  labs(title = "Bar Plot of Previous Qualification vs Target",
       x = "Previous Qualification",
       fill = "Target") +
  theme_minimal() +
  scale_fill_brewer(palette = "Set3") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```




\pagebreak
## Models

### Model 1 Association Rule Mining



#### Step 1
```{r}
# For association rule mining, we need to convert the data into transactions:
library(arules)

train.arm <- train

# Identify numeric columns
numeric_columns <- sapply(train, is.numeric)

# Discretize numeric columns
for (col in names(train)[numeric_columns]) {
  train.arm[[col]] <- discretize(train[[col]], method = "interval", breaks = 5)
}

transaction_id  <- as.character(train.arm[["transid"]])
train.arm$transid <- NULL
transactions <- as(train.arm, "transactions")

```


#### Step 2
```{r}
# Generate association rules
rules_dropout <- apriori(transactions, parameter = list(supp = 0.01, conf = 0.5, target = "rules"),
                 appearance = list(rhs = c("Target=Dropout" ), default = "lhs") , control = list(verbose=F))
rules_graduate <- apriori(transactions, parameter = list(supp = 0.01, conf = 0.5, target = "rules"),
                 appearance = list(rhs = c("Target=Graduate" ), default = "lhs") , control = list(verbose=F))
```


#### Step 3
```{r}

library(arulesViz)

# Inspect the top rules of Dropout by lift
rules_dropout_sorted <- sort(rules_dropout,decreasing = TRUE, by = "lift")
inspect(rules_dropout_sorted[1:10])

# Inspect the top rules of Dropout by confidence
rules_dropout_sorted <- sort(rules_dropout_sorted,decreasing = TRUE, by = "confidence")
inspect(rules_dropout_sorted[1:10])

#summarize the rules
summary(rules_dropout_sorted)

#visualize
plot(rules_dropout_sorted[1:10], method="graph", engine = "interactive")

```
```{r}

# Inspect Top rules of graduate

rules_graduate_sorted <- sort(rules_graduate ,decreasing = TRUE, by = "lift")
inspect(rules_graduate_sorted[1:10])
rules_graduate_sorted <- sort(rules_graduate_sorted,decreasing = TRUE, by = "confidence")
inspect(rules_graduate_sorted[1:10])
summary(rules_graduate_sorted)
plot(rules_graduate_sorted[1:10], method="graph", engine = "interactive")
```







Here are the clusters grouped by Target.  
```{r}
# ggplot(data=emdata, aes(x=Target, fill=cluster)) +
#     geom_bar(stat="count") +
#     labs(title = "K = ?") +
#     theme(plot.title = element_text(hjust=0.5),  text=element_text(size=15))
```

## k-Means Model

```{r}
train_km <- train_m
rownames(train_km) <- train[train_complete, ]$Target

set.seed(20)
```

Seven clusters for k-Means produces a pleasing result with the following parameters.

```{r, echo=TRUE}
Clusters <- kmeans(train_km, 12, iter.max = 100, nstart = 7, algorithm="Hartigan-Wong")
```

```{r}
summary(Clusters)
Clusters$cluster[1:14]
```

```{r}
train_km2 <- train[train_complete, ]
train_km2$cluster <- as.factor(Clusters$cluster)
clusplot(train_km, train_km2$cluster, color=TRUE, shade=TRUE, labels=0, lines=0)
```

This dataset does not yield to k-Means clustering, at least with all the numeric variables.
```{r}
ggplot(data=train_km2, aes(x=Target, fill=cluster)) +
    geom_bar(stat="count") +
    labs(title = "K = 12") +
    theme(plot.title = element_text(hjust=0.5),  text=element_text(size=15))
```



## Decision Tree Model

### Model 3 Decision Tree Classification 

```{r}

### For decision tree classification, we'll use the `rpart` package:

# We need to split the dataset, but since we already partitioned the dataset into train and test, we will directly use that for training our model.

# Train the decision tree model
tree_model <- rpart(Target ~ ., data = train, method = "class")
```

```{r}
# Prune the tree to simplify it
pruned_tree <- prune(tree_model, cp = tree_model$cptable[which.min(tree_model$cptable[,"xerror"]),"CP"])
```
```{r}
# Plot the pruned tree with improved readability
par(mar = c(5, 4, 4, 2) + 0.1)  # Adjust the margins as needed

rpart.plot(pruned_tree, 
           type = 2, 
           extra = 104, 
           fallen.leaves = TRUE, 
           cex = 0.8,  # Adjust text size
           box.palette = "RdYlGn", 
           shadow.col = "gray", 
           nn = TRUE,
           faclen = 0,  # Full names
           varlen = 0,  # Full variable names
           compress = TRUE)  # Compress the tree

# text(pruned_tree, use.n = TRUE)
```

```{r}
#capture the values as reference to compare in the confusion matrix
test.target <- test$Target


#drop the orginal target value
test %>% select(-Target)


#create the predictions
predictions <- predict(tree_model, newdata=test, type = "class")


# Confusion matrix
confusionMatrix(predictions, test.target)
table(predictions, test.target)
```

### Model 4 Support Vector Machine with Linear Kernel

A Support Vector machine with a linear kernel model is trained on the training data using 2-fold cross validation.  The model leverages an expanded grid to test for the following values of the C hyperparameter: 0.1, 1, 10. C is a regularization parameter that controls the balance between achieving a low error and minimizing the model complexity.  

The model also is configured to preprocess the training data to remove attributes with 0 variance, and apply centering across all of the samples.  This centers the predictors by subtracting the mean of each predictor from the data, standardizing the data so that the mean of each predictor is zero.

```{r include=FALSE}
# Define train control for SVM
# Run with 2-fold cross validation
# Compute performance metrics for multiclass classification problem
# save predictions for the final model
train_control_svm_linear = trainControl(
  method = "cv",
  number = 2,  # 2-fold cross-validation
  summaryFunction = multiClassSummary,
  savePredictions = "final"
)

#create a dataframe to specify the values of the C hyper-parameter (cost) to try when tuning the model.
#C is a regularization parameter that controls the balance between achieving a low error and minimizing the model complexity.
#A higher C value means the model will fit the training data more closely.
#A lower C value means the model will be more general.
tune_grid = expand.grid(C = c(0.1, 1, 10))

# Train SVM model with linear kernel and preprocessing included directly in the train function
# Pre-process removes attributes with 0 variance apply centering across all samples
svm_linear_model = caret::train(
  Target ~ ., 
  data = svm_train, 
  method = "svmLinear",
  trControl = train_control_svm_linear,
  preProcess = c("zv","center"),  
  tuneGrid = tune_grid
)
```


The following shows the SVM linear model statistics for each value of the C hyper-parameter used to tune the model:

```{r echo=FALSE}
# View SVM linear model statistics
print(svm_linear_model)
```

The following plot shows the Accuracy of the SVM Linear model against the 3 cost hyperparameters.

```{r echo=FALSE}
# Plot the SMV Linear model performance
plot(svm_linear_model)
```

The following reports the Confusion Matrix and Accuracy of the SVM Linear model with the highest accuracy (C=0.1).

```{r echo=FALSE}
# View confusion matrix of out-of-fold predictions
svm_out_of_fold_preds = svm_linear_model$pred
svm_conf_matrix = confusionMatrix(svm_out_of_fold_preds$pred, svm_out_of_fold_preds$obs)
svm_conf_matrix
```

The following reports the optimal C value reported by the SVM Linear model generation (C=0.1).

```{r echo=FALSE}
#view the optimal parameters
svm_linear_model$bestTune
```



### Model 5 Support Vector Machine with Polynomial Kernel
Next, a Support Vector machine with a polynomial kernel model is trained on the training data using 2-fold cross validation.  The model is configured to leverage the following multiple hyperparameters: C, Degree, and Scale.  Building the model with multiple hyperparameters with multiple values is implemented to improve the accuracy of the model based on the optimal combination of hyperparameter values.  


The C hyperparameter is a regularization parameter that controls the balance between achieving a low error and minimizing the model complexity.  The following values of the C hyperparameter are used by the model: 0.1, 1, 10.

For polynomial kernel SVMs, degree determines the degree of the polynomial used in the kernel function, affects the complexity of the decision boundary, and controls the dimensionality of the feature space after transformation. A higher degree results in a higher-dimensional space.  The following values of the Degree hyperparameter are used by the model: 2, 3, 4.

A low Degree (e.g., 2): A lower degree polynomial kernel creates simpler decision boundaries. It captures simpler relationships between the features and the target variable. With a degree of 2, the polynomial kernel generates interaction terms and quadratic features. Degree 2: Adds quadratic terms and interactions, making the model capable of capturing more complex relationships than a linear model.  

A high Degree (e.g., 3, 4, or more) creates more complex decision boundaries, captures more intricate relationships and interactions between features, which helps with data that is more complex but also increases the risk of over-fitting. Degree 3 and Above: These degrees add even higher-order terms, which increases the model’s ability to fit intricate patterns in the training data.

The Scale value used is calculated as a ratio of the number of features in the dataset (0.0278).  If scale is a small value, it effectively makes the polynomial transformation more sensitive to variations in input features. This can lead to more complex decision boundaries. For this analysis, the scale property for the polynomial kernel is set as a constant.

The model also is configured to preprocess the training data to remove attributes with 0 variance, and apply centering across all of the samples.  This centers the predictors by subtracting the mean of each predictor from the data, standardizing the data so that the mean of each predictor is zero.

```{r include=FALSE}
# Define train control for SVM
# Run with 2-fold cross validation
# Compute performance metrics for multiclass classification problem
# save predictions for the final model

train_control_svm_poly = trainControl(
  method = "cv",
  number = 2,  # 2-fold cross-validation
  summaryFunction = multiClassSummary,
  savePredictions = "final"
)

# Calculate the number of features in the training data 
# excluding 1 data to account for the Target column
num_features = ncol(svm_train) - 1

# Calculate the scale value as 1 / number of features
scale_value = 1 / num_features

#create a data frame of all possible hyper parameter combinations for tuning the SVM with polynomial kernel.
tune_grid_svm_poly = expand.grid(C = c(0.1, 1, 10), degree = c(2, 3, 4), scale=scale_value)  # Only tuning C and degree, not scale


# Train SVM model with polynomial kernel and preprocessing included directly in the train function
svm_poly_model = caret::train(
  Target ~ ., 
  data = svm_train, 
  method = "svmPoly",  
  trControl = train_control_svm_poly,
  preProcess = c("zv", "center"),  # remove attributes with 0 variance across all samples, apply centering
  tuneGrid = tune_grid_svm_poly  
)
```


The following shows the SVM Polynomial model statistics for each combination hyperparameters used to tune the model (C and Degree, only, as Scale was set at a constant value):

```{r echo=FALSE}
# View model statistics
print(svm_poly_model)
```


The following plot shows the Accuracy of the SVM Polynomial model against the 3 cost and Degree hyperparameters.

```{r echo=FALSE}
# Plot model performance
plot(svm_poly_model)
```


The following reports the Confusion Matrix and Accuracy of the SVM Polynomial model with the highest accuracy (C=1.0, Degree=2).

```{r echo=FALSE}
# View confusion matrix of out-of-fold predictions
svm_poly_out_of_fold_preds = svm_poly_model$pred
svm_conf_matrix = confusionMatrix(svm_poly_out_of_fold_preds$pred, svm_poly_out_of_fold_preds$obs)
print(svm_conf_matrix)
```

The following reports the optimal hyperparameters reported by the SVM Polynomial model generation.

```{r echo=FALSE}
#view the optimal parameters
svm_poly_model$bestTune
```



## Additional Models

# Dimensionality Reduction

```{r}
# Perform PCA
pca <- prcomp(train %>% select(where(is.numeric)), center = TRUE, scale. = TRUE)

# Summary of PCA
summary(pca)

# Append PCA results to the dataset
train_pca <- as.data.frame(pca$x)
train_pca$Target <- train$Target

# Visualize PCA results
ggplot(train_pca, aes(x = PC1, y = PC2, color = Target)) +
  geom_point() +
  labs(title = "PCA of Student Success Data",
       x = "Principal Component 1",
       y = "Principal Component 2") +
  theme_minimal()


# Visualize the explained variance
fviz_eig(pca, addlabels = TRUE, ylim = c(0, 50))

```


# PCA on Selected Factors

Based on the Scree plot, it looks like the first few principal components explain a significant portion of the variance. Let’s decide to select the first two principal components for further analysis.

```{r}

# Select the number of principal components based on the Scree plot
selected_pcs <- 2

# Transform the data using the selected principal components
train_pca_selected <- as.data.frame(pca$x[, 1:selected_pcs])
train_pca_selected$Target <- train$Target

# Visualize the explained variance
fviz_eig(pca, addlabels = TRUE, ylim = c(0, 50))

# Visualize PCA results
ggplot(train_pca_selected, aes(x = PC1, y = PC2, color = Target)) +
  geom_point() +
  labs(title = "PCA of Student Success Data (Selected Components)",
       x = "Principal Component 1",
       y = "Principal Component 2") +
  theme_minimal()


```

# MODEL 6 - NAIVE BAYES

# Naive Bayes with k-fold Cross-Validation on Non-PCA Data
```{r}
# Set up k-fold cross-validation
kfolds <- 10
folds <- createFolds(train$Target, k = kfolds)

AllResults_non_pca <- list()
AllLabels_non_pca <- list()

for (k in 1:kfolds) {
  fold_train <- train[folds[[k]], ]
  fold_test <- train[-folds[[k]], ]
  
  # Train Naive Bayes Model
  naive_bayes_model <- naiveBayes(Target ~ ., data = fold_train)
  
  # Predict on Test Data
  nb_Pred <- predict(naive_bayes_model, newdata = fold_test)
  
  #Visualize
  plot(nb_Pred, ylab= "Density", main = "Naive Bayes Plot")
  
  # Ensure predictions and actual labels are factors with the same levels
  nb_Pred <- factor(nb_Pred, levels = unique(c(levels(nb_Pred), levels(fold_test$Target))))
  fold_test$Target <- factor(fold_test$Target, levels = unique(c(levels(nb_Pred), levels(fold_test$Target))))
  
  # Visualize Naive Bayes Predictions
  plot <- ggplot(data.frame(Prediction = nb_Pred), aes(x = Prediction)) +
    geom_density(fill = "blue", alpha = 0.5) +
    labs(title = paste("Naive Bayes Plot - Fold", k), y = "Density") +
    theme_minimal()
  print(plot)
  
  # Evaluate Model
  conf_matrix <- confusionMatrix(nb_Pred, fold_test$Target)
  print(conf_matrix)
  
  # Calculate accuracy
  accuracy <- sum(diag(conf_matrix$table)) / sum(conf_matrix$table)
  print(paste("Accuracy: Fold", k, "-", round(accuracy * 100, 2), "%", sep = " "))
  
  # Accumulate results from each fold
  AllResults_non_pca <- c(AllResults_non_pca, nb_Pred)
  AllLabels_non_pca <- c(AllLabels_non_pca, fold_test$Target)
}

# Confusion Matrix (across all folds)
final_conf_matrix_non_pca <- table(unlist(AllResults_non_pca), unlist(AllLabels_non_pca))
print(final_conf_matrix_non_pca)

# Calculate accuracy from the confusion matrix
nb_accuracy_non_pca <- sum(diag(final_conf_matrix_non_pca)) / sum(final_conf_matrix_non_pca)
print(paste("Overall Accuracy (Non-PCA): ", round(nb_accuracy_non_pca * 100, 2), "%", sep = ""))

# Plot Confusion Matrix as Heatmap
heatmap_data_non_pca <- as.matrix(final_conf_matrix_non_pca)
pheatmap(heatmap_data_non_pca, main = "Confusion Matrix Heatmap (Non-PCA)", color = colorRampPalette(c("white", "blue"))(50))

# Plotting ROC Curve
roc_curve_non_pca <- roc(unlist(AllLabels_non_pca), as.numeric(unlist(AllResults_non_pca)))
ggroc(roc_curve_non_pca) +
  ggtitle("ROC Curve (Non-PCA)") +
  xlab("1 - Specificity") +
  ylab("Sensitivity")



```
# Naive Bayes with K folds validation on Selected PCA Data
```{r}
# Set up k-fold cross-validation
folds_pca <- createFolds(train_pca_selected$Target, k = kfolds)

AllResults_pca <- list()
AllLabels_pca <- list()

for (k in 1:kfolds) {
  fold_train <- train_pca_selected[folds_pca[[k]], ]
  fold_test <- train_pca_selected[-folds_pca[[k]], ]
  
  # Train Naive Bayes Model
  naive_bayes_model <- naiveBayes(Target ~ ., data = fold_train)
  
  # Predict on Test Data
  nb_Pred <- predict(naive_bayes_model, newdata = fold_test)
  
  #Visualize
  plot(nb_Pred, ylab= "Density", main = "Naive Bayes Plot")
  
  # Ensure predictions and actual labels are factors with the same levels
  nb_Pred <- factor(nb_Pred, levels = unique(c(levels(nb_Pred), levels(fold_test$Target))))
  fold_test$Target <- factor(fold_test$Target, levels = unique(c(levels(nb_Pred), levels(fold_test$Target))))
  
  # Visualize Naive Bayes Predictions
  plot <- ggplot(data.frame(Prediction = nb_Pred), aes(x = Prediction)) +
    geom_density(fill = "blue", alpha = 0.5) +
    labs(title = paste("Naive Bayes Plot - Fold", k), y = "Density") +
    theme_minimal()
  print(plot)
  
  
  # Evaluate Model
  conf_matrix <- confusionMatrix(nb_Pred, fold_test$Target)
  print(conf_matrix)
  
  # Calculate accuracy
  accuracy <- sum(diag(conf_matrix$table)) / sum(conf_matrix$table)
  print(paste("Accuracy: Fold", k, "-", round(accuracy * 100, 2), "%", sep = " "))
  
  # Accumulate results from each fold
  AllResults_pca <- c(AllResults_pca, nb_Pred)
  AllLabels_pca <- c(AllLabels_pca, fold_test$Target)
}

# Confusion Matrix (across all folds)
final_conf_matrix_pca <- table(unlist(AllResults_pca), unlist(AllLabels_pca))
print(final_conf_matrix_pca)

# Calculate accuracy from the confusion matrix
nb_accuracy_pca <- sum(diag(final_conf_matrix_pca)) / sum(final_conf_matrix_pca)
print(paste("Overall Accuracy (PCA): ", round(nb_accuracy_pca * 100, 2), "%", sep = ""))

# Plot Confusion Matrix as Heatmap
heatmap_data_pca <- as.matrix(final_conf_matrix_pca)
pheatmap(heatmap_data_pca, main = "Confusion Matrix Heatmap (PCA)", color = colorRampPalette(c("white", "blue"))(50))

# Plotting ROC Curve
roc_curve_pca <- roc(unlist(AllLabels_pca), as.numeric(unlist(AllResults_pca)))
ggroc(roc_curve_pca) +
  ggtitle("ROC Curve (PCA)") +
  xlab("1 - Specificity") +
  ylab("Sensitivity")



```
# Naive Bayes with K folds on PCA data

```{r}
# Set up k-fold cross-validation
folds_pca <- createFolds(train_pca$Target, k = kfolds)

AllResults_pca <- list()
AllLabels_pca <- list()

for (k in 1:kfolds) {
  fold_train <- train_pca[folds_pca[[k]], ]
  fold_test <- train_pca[-folds_pca[[k]], ]
  
  # Train Naive Bayes Model
  naive_bayes_model <- naiveBayes(Target ~ ., data = fold_train)
  
  # Predict on Test Data
  nb_Pred <- predict(naive_bayes_model, newdata = fold_test)
  
  #Visualize
  plot(nb_Pred, ylab= "Density", main = "Naive Bayes Plot")
  
  # Ensure predictions and actual labels are factors with the same levels
  nb_Pred <- factor(nb_Pred, levels = unique(c(levels(nb_Pred), levels(fold_test$Target))))
  fold_test$Target <- factor(fold_test$Target, levels = unique(c(levels(nb_Pred), levels(fold_test$Target))))
  
  # Visualize Naive Bayes Predictions
  plot <- ggplot(data.frame(Prediction = nb_Pred), aes(x = Prediction)) +
    geom_density(fill = "blue", alpha = 0.5) +
    labs(title = paste("Naive Bayes Plot - Fold", k), y = "Density") +
    theme_minimal()
  print(plot)
  
  # Evaluate Model
  conf_matrix <- confusionMatrix(nb_Pred, fold_test$Target)
  print(conf_matrix)
  
  # Calculate accuracy
  accuracy <- sum(diag(conf_matrix$table)) / sum(conf_matrix$table)
  print(paste("Accuracy: Fold", k, "-", round(accuracy * 100, 2), "%", sep = " "))
  
  # Accumulate results from each fold
  AllResults_pca <- c(AllResults_pca, nb_Pred)
  AllLabels_pca <- c(AllLabels_pca, fold_test$Target)
}

# Confusion Matrix (across all folds)
final_conf_matrix_pca <- table(unlist(AllResults_pca), unlist(AllLabels_pca))
print(final_conf_matrix_pca)

# Calculate accuracy from the confusion matrix
nb_accuracy_pca <- sum(diag(final_conf_matrix_pca)) / sum(final_conf_matrix_pca)
print(paste("Overall Accuracy (PCA): ", round(nb_accuracy_pca * 100, 2), "%", sep = ""))

# Plot Confusion Matrix as Heatmap
heatmap_data_pca <- as.matrix(final_conf_matrix_pca)
pheatmap(heatmap_data_pca, main = "Confusion Matrix Heatmap (PCA)", color = colorRampPalette(c("white", "blue"))(50))

# Plotting ROC Curve
roc_curve_pca <- roc(unlist(AllLabels_pca), as.numeric(unlist(AllResults_pca)))
ggroc(roc_curve_pca) +
  ggtitle("ROC Curve (PCA)") +
  xlab("1 - Specificity") +
  ylab("Sensitivity")


```




# Model 7 - RANDOM FOREST
# Random Forest with k-fold Cross-Validation on Non-PCA Data

```{r}
# Set up k-fold cross-validation
train_control <- trainControl(method = "cv", number = 10)

# Train the model on non-PCA data
rf_model_non_pca <- train(Target ~ ., data = train, method = "rf", trControl = train_control)

# Predict on the test set
predictions_non_pca <- predict(rf_model_non_pca, newdata = test)

# Confusion matrix and accuracy for non-PCA data
conf_matrix_non_pca <- confusionMatrix(predictions_non_pca, test$Target)
print(conf_matrix_non_pca)

# Calculate and print accuracy for non-PCA data
rf_accuracy_non_pca <- conf_matrix_non_pca$overall['Accuracy']
print(paste("Random Forest Accuracy (Non-PCA):", rf_accuracy_non_pca))


```

# Random Forest with k-fold Cross-Validation on PCA Data

```{r}
# Train the model on PCA data
rf_model_pca <- train(Target ~ ., data = train_pca, method = "rf", trControl = train_control)

# Predict on the test set
test_pca <- as.data.frame(predict(pca, newdata = test %>% select(where(is.numeric))))
test_pca$Target <- test$Target
predictions_pca <- predict(rf_model_pca, newdata = test_pca)

# Confusion matrix and accuracy for PCA data
conf_matrix_pca <- confusionMatrix(predictions_pca, test$Target)
print(conf_matrix_pca)

# Calculate and print accuracy for PCA data
rf_accuracy_pca <- conf_matrix_pca$overall['Accuracy']
print(paste("Random Forest Accuracy (PCA):", rf_accuracy_pca))

```


# Random Forest with K fold Cross Validation on Selected PCA Data

```{r}

# Train the model on selected PCA data
rf_model_pca_selected <- train(Target ~ ., data = train_pca_selected, method = "rf", trControl = train_control)

# Transform the test data using the same PCA transformation
test_pca_selected <- as.data.frame(predict(pca, newdata = test %>% select(where(is.numeric)))[, 1:selected_pcs])
test_pca_selected$Target <- test$Target

# Predict on the test set
predictions_pca_selected <- predict(rf_model_pca_selected, newdata = test_pca_selected)

# Confusion matrix and accuracy for selected PCA data
conf_matrix_pca_selected <- confusionMatrix(predictions_pca_selected, test$Target)
print(conf_matrix_pca_selected)

# Calculate and print accuracy for selected PCA data
rf_accuracy_pca_selected <- conf_matrix_pca_selected$overall['Accuracy']
print(paste("Random Forest Accuracy (Selected PCA):", rf_accuracy_pca_selected))




```
# Random Forest with different number of trees on Non PCA data

```{r}

# Define a grid of different numbers of trees
tune_grid <- expand.grid(.mtry = c(2, 4, 6, 8, 10))

# Train the model on non-PCA data with different numbers of trees
rf_model_non_pca <- train(Target ~ ., data = train, method = "rf", trControl = train_control, tuneGrid = tune_grid)

# Predict on the test set
predictions_non_pca <- predict(rf_model_non_pca, newdata = test)

# Confusion matrix and accuracy for non-PCA data
conf_matrix_non_pca <- confusionMatrix(predictions_non_pca, test$Target)
print(conf_matrix_non_pca)

# Calculate and print accuracy for non-PCA data
rf_accuracy_non_pca <- conf_matrix_non_pca$overall['Accuracy']
print(paste("Random Forest Accuracy (Non-PCA):", rf_accuracy_non_pca))
```

# Random Forest with different Numbers of Trees on Selected PCA data

```{r}

# Train the model on selected PCA data with different numbers of trees
rf_model_pca_selected <- train(Target ~ ., data = train_pca_selected, method = "rf", trControl = train_control, tuneGrid = tune_grid)

# Transform the test data using the same PCA transformation
test_pca_selected <- as.data.frame(predict(pca, newdata = test %>% select(where(is.numeric)))[, 1:selected_pcs])
test_pca_selected$Target <- test$Target

# Predict on the test set
predictions_pca_selected <- predict(rf_model_pca_selected, newdata = test_pca_selected)

# Confusion matrix and accuracy for selected PCA data
conf_matrix_pca_selected <- confusionMatrix(predictions_pca_selected, test$Target)
print(conf_matrix_pca_selected)

# Calculate and print accuracy for selected PCA data
rf_accuracy_pca_selected <- conf_matrix_pca_selected$overall['Accuracy']
print(paste("Random Forest Accuracy (Selected PCA):", rf_accuracy_pca_selected))


```
# Random Forest with different Numbers of Trees on PCA data

```{r}

# Train the model on selected PCA data with different numbers of trees
rf_model_pca <- train(Target ~ ., data = train_pca, method = "rf", trControl = train_control, tuneGrid = tune_grid)

# Transform the test data using the same PCA transformation
test_pca <- as.data.frame(predict(pca, newdata = test %>% select(where(is.numeric)))[, 1:selected_pcs])
test_pca$Target <- test$Target

# Predict on the test set
predictions_pca <- predict(rf_model_pca, newdata = test_pca)

# Confusion matrix and accuracy for selected PCA data
conf_matrix_pca <- confusionMatrix(predictions_pca, test$Target)
print(conf_matrix_pca)

# Calculate and print accuracy for selected PCA data
rf_accuracy_pca <- conf_matrix_pca$overall['Accuracy']
print(paste("Random Forest Accuracy (PCA):", rf_accuracy_pca))
```


\pagebreak
# Conclusions



\pagebreak
# Limitations of the Analysis and/or Available Data


\pagebreak
# Conclusions



\pagebreak
# Limitations of the Analysis and/or Available Data




\pagebreak
# Bibliography

Realinho,Valentim, Vieira Martins,Mónica, Machado,Jorge, and Baptista,Luís. (2021). Predict Students' Dropout and Academic Success. UCI Machine Learning Repository. https://doi.org/10.24432/C5MC89.

